{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c382383",
   "metadata": {},
   "source": [
    "# <span style=\"color:#ff5f27\"> 👨🏻‍🏫 PyTorch Model and Sklearn Transformation Functions Registration in the Model Registry</span>\n",
    "\n",
    "In this notebook you will see how to **register Sklearn Transformation Functions and PyTorch model** in Hopsworks Model Registry, how to **retrieve** them and then use for **batch and feature vector prediction**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3994e496",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">🗄️ Table of Contents</span>\n",
    "- [📝 Imports](#1)\n",
    "- [💽 Loading Data](#2)\n",
    "- [🔮 Connecting to Hopsworks Feature Store](#3)\n",
    "- [🪄 Creating Feature Groups](#4)\n",
    "- [🖍 Feature View Creation](#5)\n",
    "- [👩🏻‍🔬 Data Transformation](#6)\n",
    "- [👔 Transformer instances fit](#7)\n",
    "- [🧬 Modeling](#8)\n",
    "- [💾 Saving the Model and Transformation Functions](#9)\n",
    "- [📮 Retrieving the Model and Transformation Functions from Model Registry](#10)\n",
    "- [👨🏻‍⚖️ Batch Prediction](#11)\n",
    "- [👨🏻‍⚖️ Serving Feature Vector Prediction](#12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8743b40",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## <span style='color:#ff5f27'> 📝 Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e0c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626ca429",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## <span style=\"color:#ff5f27;\"> 💽 Loading Data </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7aaf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_original = pd.read_csv(\"https://repo.hops.works/dev/davit/air_quality/backfill_pm2_5_eu.csv\")\n",
    "# Generate a binary target column\n",
    "df_original['target'] = np.random.choice([0, 1], size=len(df_original))\n",
    "df_original.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd983ab",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## <span style=\"color:#ff5f27;\"> 🔮 Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f77b7b",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## <span style=\"color:#ff5f27;\">🪄 Creating Feature Groups</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = fs.get_or_create_feature_group(\n",
    "    name='feature_group_online',\n",
    "    description='Online Feature Group',\n",
    "    version=1,\n",
    "    primary_key=['city_name', 'date'],\n",
    "    online_enabled=True,\n",
    ")    \n",
    "feature_group.insert(df_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6e3352",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## <span style=\"color:#ff5f27;\"> 🖍 Feature View Creation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd09628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Query object\n",
    "query = feature_group.select_except(['date'])\n",
    "\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='serving_fv',\n",
    "    version=1,\n",
    "    query=query,\n",
    "    labels=['target']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f554ced8",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> 🏋️ Training Dataset Creation</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb20081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train-test split dataset\n",
    "td_version, job = feature_view.create_train_test_split(\n",
    "    test_size=0.1,\n",
    "    description='Description of the dataset',\n",
    "    data_format='csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1502740c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">🪝 Training Dataset Retrieval</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a938b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the train-test split\n",
    "X_train, X_test, y_train, y_test = feature_view.get_train_test_split(\n",
    "    training_dataset_version=td_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a830bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8342245",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2a6bd8",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## <span style=\"color:#ff5f27;\">👩🏻‍🔬 Data Transformation</span>\n",
    "\n",
    "For Data Transformation let's create two functions: `to_df` and `transform_data`.\n",
    "\n",
    "- `to_df` function will transform a feature vector(s) list into a pandas DataFrame.\n",
    "- `transform_data` function will apply transformations to the input data using OneHotEncoder and StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(feature_vector):\n",
    "    \"\"\"\n",
    "    Convert a feature vector or a list of feature vectors into a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        feature_vector (a list, or list of lists): \n",
    "            A feature vector or a list of feature vectors. A feature vector is \n",
    "            represented as a list containing two elements: the first \n",
    "            element corresponds to the city name (categorical feature), and the \n",
    "            second element corresponds to the PM2.5 value (numerical feature).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame representing the feature vector(s). \n",
    "        The DataFrame will have two columns: 'city_name' for the city names \n",
    "        and 'pm2_5' for the corresponding PM2.5 values.\n",
    "\n",
    "    Example:\n",
    "        >>> feature_vector = ['New York', 15.3]\n",
    "        >>> to_df(feature_vector)\n",
    "           city_name  pm2_5\n",
    "        0  New York   15.3\n",
    "\n",
    "        >>> multiple_vectors = [['New York', 15.3], ['Los Angeles', 10.7]]\n",
    "        >>> to_df(multiple_vectors)\n",
    "          city_name  pm2_5\n",
    "        0  New York   15.3\n",
    "        1  Los Angeles 10.7\n",
    "    \"\"\"\n",
    "    if isinstance(feature_vector[0], list): \n",
    "        city_names = [vector[0] for vector in feature_vector]\n",
    "        pm2_5_values = [vector[1] for vector in feature_vector]\n",
    "        data = pd.DataFrame(\n",
    "            {\n",
    "                'city_name': city_names,\n",
    "                'pm2_5': pm2_5_values,\n",
    "            }\n",
    "        )\n",
    "        return data\n",
    "\n",
    "    data = pd.DataFrame(\n",
    "            {\n",
    "                'city_name': [feature_vector[0]],\n",
    "                'pm2_5': [feature_vector[1]],\n",
    "            }\n",
    "        )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data, one_hot_encoder, standard_scaler):\n",
    "    \"\"\"\n",
    "    Apply transformations to the input data using OneHotEncoder and StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "        data (pandas.DataFrame):\n",
    "            The input DataFrame containing the columns 'city_name' (categorical feature)\n",
    "            and 'pm2_5' (numerical feature) to be transformed.\n",
    "\n",
    "        one_hot_encoder (sklearn.preprocessing.OneHotEncoder):\n",
    "            The fitted OneHotEncoder object used to encode the 'city_name' column into binary vectors.\n",
    "\n",
    "        standard_scaler (sklearn.preprocessing.StandardScaler):\n",
    "            The fitted StandardScaler object used to standardize the 'pm2_5' column.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame:\n",
    "            A new DataFrame with the 'city_name' column encoded and the 'pm2_5' column\n",
    "            standardized using StandardScaler. The new DataFrame contains all the original\n",
    "            columns except 'city_name', and the encoded 'city_name' columns as binary vectors.\n",
    "    \"\"\"\n",
    "    # Transform the 'city_name' column using OneHotEncoder\n",
    "    city_encoded = one_hot_encoder.transform(data[['city_name']])\n",
    "\n",
    "    # Create a new DataFrame with the encoded values\n",
    "    encoded_df = pd.DataFrame(city_encoded, columns=one_hot_encoder.categories_[0])\n",
    "\n",
    "    # Concatenate the encoded DataFrame with the original DataFrame\n",
    "    data = pd.concat([data.drop('city_name', axis=1), encoded_df], axis=1)\n",
    "    \n",
    "    # Transform the 'pm2_5' column using StandardScaler\n",
    "    data['pm2_5'] = standard_scaler.transform(data[['pm2_5']])\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7979c69",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "### <span style=\"color:#ff5f27;\"> 👔 Transformer instances fit</span>\n",
    "\n",
    "The next step is to create instances of OneHotEncoder and StandardScaler transformers and fit them on X_train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5fd98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OneHotEncoder and StandardScaler\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "standard_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder.fit(X_train[['city_name']])\n",
    "standard_scaler.fit(X_train[['pm2_5']])\n",
    "print('✅ Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c958cde",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">⛳️ Train Data Transformation</span>\n",
    "\n",
    "Now let's use `transform_data` function to transform `X_train` and `X_test` using fitted `OneHotEncoder` and `StandardScaler` transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = transform_data(X_train, one_hot_encoder, standard_scaler)\n",
    "X_train_transformed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f90aa",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">⛳️ Test Data Transformation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16888a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = transform_data(X_test, one_hot_encoder, standard_scaler)\n",
    "X_test_transformed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09cf48d",
   "metadata": {},
   "source": [
    "<a name='8'></a>\n",
    "## <span style=\"color:#ff5f27;\">🧬 Modeling</span>\n",
    "\n",
    "In the Modeling part, you will build a PyTorch Binary Classification model and fit it on the transformed X_train dataset.\n",
    "\n",
    "In addition, let's create the `to_tensor` function in order to **transform pandas dataframe** into **PyTorch tensor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5be4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(dataframe):\n",
    "    \"\"\"\n",
    "    Convert a pandas DataFrame to a PyTorch tensor.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pandas.DataFrame):\n",
    "            The input DataFrame to be converted to a tensor.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor:\n",
    "            A PyTorch tensor containing the values from the input DataFrame.\n",
    "            The data type of the tensor is torch.float32.\n",
    "    \"\"\"\n",
    "    return torch.tensor(dataframe.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13238259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_transformed_tensor = to_tensor(X_train_transformed)\n",
    "y_train_tensor = to_tensor(y_train)\n",
    "\n",
    "X_train_transformed_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d780083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model class\n",
    "class BinaryClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(BinaryClassificationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "input_dim = X_train_transformed_tensor.shape[1]\n",
    "model = BinaryClassificationModel(input_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "num_batches = len(X_train_transformed_tensor) // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(num_batches):\n",
    "        # Prepare mini-batches\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_X, batch_y = X_train_transformed_tensor[start_idx:end_idx], y_train_tensor[start_idx:end_idx]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y.view(-1, 1))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training progress\n",
    "        if (i + 1) % 1786 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{num_batches}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bedc3e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">🗄 Model Registry</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a73fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbde875",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">⚙️ Model Schema</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c52621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "input_schema = Schema(X_train_transformed.values)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f6cb84",
   "metadata": {},
   "source": [
    "<a name='9'></a>\n",
    "### <span style=\"color:#ff5f27;\">💾 Saving the Model and Transformation Functions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"torch_tf_model\"\n",
    "\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Save Transformation Functions\n",
    "joblib.dump(one_hot_encoder, model_dir + '/one_hot_encoder.pkl')\n",
    "joblib.dump(standard_scaler, model_dir + '/standard_scaler.pkl')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, model_dir + '/torch_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7415dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model in the model registry\n",
    "model = mr.torch.create_model(\n",
    "    name=\"torch_model\",\n",
    "    description=\"PyTorch model\",\n",
    "    input_example=X_train.sample(),\n",
    "    model_schema=model_schema,\n",
    ")\n",
    "\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4e238f",
   "metadata": {},
   "source": [
    "<a name='10'></a>\n",
    "## <span style=\"color:#ff5f27;\"> 📮 Retrieving the Model and Transformation Functions from Model Registry </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b287444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve your model from the model registry\n",
    "retrieved_model = mr.get_model(\n",
    "    name=\"torch_model\",\n",
    "    version=1\n",
    ")\n",
    "saved_model_dir = retrieved_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9854b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the PyTorch model\n",
    "retrieved_torch_model = joblib.load(saved_model_dir + \"/torch_classifier.pkl\")\n",
    "\n",
    "# Retrieve Transformation Functions\n",
    "one_hot_encoder = joblib.load(saved_model_dir + \"/one_hot_encoder.pkl\")\n",
    "standard_scaler = joblib.load(saved_model_dir + \"/standard_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e2e23e",
   "metadata": {},
   "source": [
    "<a name='11'></a>\n",
    "## <span style=\"color:#ff5f27;\"> 👨🏻‍⚖️ Batch Prediction </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94123860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise feature view to retrieve batch data\n",
    "feature_view.init_batch_scoring(training_dataset_version=td_version)\n",
    "\n",
    "# Retrieve batch data\n",
    "batch_data = feature_view.get_batch_data()\n",
    "batch_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d1d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations to the batch data using transform_data function\n",
    "batch_data_transformed = transform_data(batch_data, one_hot_encoder, standard_scaler)\n",
    "batch_data_transformed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b96bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict batch data using retrieved model\n",
    "predictions_batch = retrieved_torch_model(to_tensor(batch_data_transformed))\n",
    "predictions_batch[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4631d",
   "metadata": {},
   "source": [
    "<a name='12'></a>\n",
    "## <span style=\"color:#ff5f27;\"> 👨🏻‍⚖️ Serving Feature Vector Prediction</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise feature view to retrieve feature vector\n",
    "feature_view.init_serving(1)\n",
    "\n",
    "# Retrieve a feature vector\n",
    "feature_vector = feature_view.get_feature_vector(\n",
    "    entry = {\n",
    "        \"city_name\": 'Amsterdam',\n",
    "        \"date\": '2013-01-01',\n",
    "    }\n",
    ")\n",
    "feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cbd96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform feature vector to pandas dataframe\n",
    "feature_vector_df = to_df(feature_vector)\n",
    "feature_vector_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe202dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations to the feature vector df using transform_data function\n",
    "feature_vector_transformed = transform_data(feature_vector_df, one_hot_encoder, standard_scaler)\n",
    "feature_vector_transformed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dfdbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict transformed feature vector using retrieved model\n",
    "prediction_feature_vector = retrieved_torch_model(to_tensor(feature_vector_transformed))\n",
    "prediction_feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac541e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature vectors from feature store\n",
    "feature_vectors = feature_view.get_feature_vectors(\n",
    "    entry = [\n",
    "        {\"city_name\": 'Amsterdam', \"date\": '2013-01-01'},\n",
    "        {\"city_name\": 'Amsterdam', \"date\": '2014-01-01'},\n",
    "    ]\n",
    ")\n",
    "feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert feature vectors to pandas dataframe\n",
    "feature_vectors_df = to_df(feature_vectors)\n",
    "feature_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations to the feature vectors df using transform_data function\n",
    "feature_vectors_transformed = transform_data(feature_vectors_df, one_hot_encoder, standard_scaler)\n",
    "feature_vectors_transformed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict transformed feature vectors using retrieved model\n",
    "prediction_feature_vectors = retrieved_torch_model(to_tensor(feature_vectors_transformed))\n",
    "prediction_feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1149b1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
