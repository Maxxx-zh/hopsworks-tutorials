{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609432a1",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from prophet import Prophet\n",
    "from prophet.serialize import model_to_json\n",
    "\n",
    "# Mute warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91597c8",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c88102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2984a925",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üî™ Feature Selection </span>\n",
    "\n",
    "You will start by selecting all the features you want to include for model training/inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843299b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the 'patient_info' feature group\n",
    "patient_info_fg = fs.get_feature_group(\n",
    "    name=\"patient_info\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# Retrieve the 'medical_info' feature group\n",
    "medical_info_fg = fs.get_feature_group(\n",
    "    name=\"medical_info\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# Retrieve the 'transplant_compatibility' feature group\n",
    "transplant_compatibility_fg = fs.get_feature_group(\n",
    "    name=\"transplant_compatibility\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4705fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data.\n",
    "selected_features = patient_info_fg.select_all(include_primary_key=False, include_event_time=False)\\\n",
    "    .join(medical_info_fg.select_all(include_primary_key=False, include_event_time=False))\\\n",
    "    .join(transplant_compatibility_fg.select_all(include_primary_key=False, include_event_time=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you would like to view your selected features\n",
    "#selected_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a06d44",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Transformation Functions </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f9000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f.name for f in fs.get_transformation_functions()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9345d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = fs.get_transformation_function(name=\"label_encoder\")\n",
    "\n",
    "standard_scaler = fs.get_transformation_function(name=\"standard_scaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_category = ['gender', 'age_cat', 'blood_gp', 'underlying_disease', 'gestation', 'prior_transplant', 'if_transplanted']\n",
    "\n",
    "transformation_functions_category = {\n",
    "    feature_name: label_encoder\n",
    "    for feature_name\n",
    "    in features_category\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_numerical = [\n",
    "    'age_at_list_registration', 'dialysis_duration', 'number_prior_transplant', 'cpra', 'hla_a1', 'hla_a2', 'hla_b1', 'hla_b2', 'hla_dr1', 'hla_dr2',\n",
    "]\n",
    "\n",
    "transformation_functions_numerical = {\n",
    "    feature_name: standard_scaler\n",
    "    for feature_name\n",
    "    in features_numerical\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b7565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join transformation_functions_category and transformation_functions_numerical dictionaries into one\n",
    "transformation_functions = transformation_functions_category | transformation_functions_numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d987299d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Feature View Creation </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b76818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'medical_features' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='medical_features',\n",
    "    version=1,\n",
    "    query=selected_features,\n",
    "    labels=[\"duration\"],\n",
    "    transformation_functions=transformation_functions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96ea75",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d3446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split date with percentage \n",
    "df = patient_info_fg.read()\n",
    "\n",
    "def split_dfs(df): \n",
    "    df = df.sort_values(by='date') \n",
    "    trainvals = df[:int(len(df)*0.8)] \n",
    "    testvals = df[int(len(df)*0.8):] \n",
    "    return {\n",
    "        'train_start': min(trainvals.date).date(), \n",
    "        'train_end': max(trainvals.date).date(), \n",
    "        'test_start': min(testvals.date).date(), \n",
    "        'test_end': max(testvals.date).date(),\n",
    "    }\n",
    "\n",
    "split_dict = split_dfs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a8dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59774ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = feature_view.train_test_split(\n",
    "    train_start=split_dict['train_start'],\n",
    "    train_end=split_dict['train_end'],\n",
    "    test_start=split_dict['test_start'],\n",
    "    test_end=split_dict['test_end'],    \n",
    "    event_time=True,\n",
    ")\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e020d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c1a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the X_train DataFrame based on the \"datetime\" column in ascending order\n",
    "X_train = X_train.sort_values(\"date\")\n",
    "# Reindex the y_train Series to match the order of rows in the sorted X_train DataFrame\n",
    "y_train = y_train.reindex(X_train.index)\n",
    "\n",
    "# Sort the X_test DataFrame based on the \"datetime\" column in ascending order\n",
    "X_test = X_test.sort_values(\"date\")\n",
    "# Reindex the y_test Series to match the order of rows in the sorted X_test DataFrame\n",
    "y_test = y_test.reindex(X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8df883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['y'] = y_train\n",
    "X_train['ds'] = X_train.date\n",
    "X_train['ds'] = pd.to_datetime(X_train.ds)\n",
    "X_train['ds'] = X_train.ds.map(lambda x: x.replace(tzinfo=None))\n",
    "X_train.drop(columns=[\"date\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c61422",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['ds'] = X_test.date\n",
    "X_test['ds'] = pd.to_datetime(X_test.ds)\n",
    "X_test['ds'] = X_test.ds.map(lambda x: x.replace(tzinfo=None))\n",
    "X_test.drop(columns=[\"date\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8cc891",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üß¨ Modeling</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccbc1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Prophet model with the appropriate seasonalities\n",
    "model = Prophet(\n",
    "    daily_seasonality=False,\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=True,\n",
    ")\n",
    "\n",
    "# Add monthly seasonality with a period of 30.5 days (average length of a month)\n",
    "model.add_seasonality(\n",
    "    name='monthly', \n",
    "    period=30.5, \n",
    "    fourier_order=5,\n",
    "    mode='additive',\n",
    ")\n",
    "\n",
    "# Add the additional regressors\n",
    "additional_regressors = [\n",
    "    'age_at_list_registration','cpra', 'hla_a1', 'hla_a2', 'hla_b1', 'hla_b2', 'hla_dr1', 'hla_dr2',\n",
    "]\n",
    "\n",
    "for regressor in additional_regressors:\n",
    "    model.add_regressor(regressor)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a3a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model.predict(X_test)\n",
    "\n",
    "# Summarize the forecast\n",
    "print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head())\n",
    "\n",
    "# Plot the forecast\n",
    "fig_forecast = model.plot(forecast)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecast components\n",
    "fig_components = model.plot_components(forecast)\n",
    "fig_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAE between expected and predicted values for december\n",
    "y_pred = forecast['yhat']\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "metrics = {\n",
    "    \"mae\": round(mae,2)\n",
    "}\n",
    "print('üéØ MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2024739",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚öôÔ∏è Model Schema</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc442c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "# Define the input schema using the values of X_test\n",
    "input_schema = Schema(X_test.values)\n",
    "\n",
    "# Define the output schema using y_train\n",
    "output_schema = Schema(y_train)\n",
    "\n",
    "# Create a ModelSchema object specifying the input and output schemas\n",
    "model_schema = ModelSchema(\n",
    "    input_schema=input_schema, \n",
    "    output_schema=output_schema,\n",
    ")\n",
    "\n",
    "# Convert the model schema to a dictionary for further inspection or serialization\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6561dc",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üìù Register model</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where the model will be saved\n",
    "model_dir = \"forecast_model\"\n",
    "\n",
    "# Check if the directory exists, and create it if it doesn't\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save the trained model\n",
    "with open(model_dir + '/serialized_model.json', 'w') as fout:\n",
    "    fout.write(model_to_json(model))  # Save model\n",
    "    \n",
    "# Save the forecast plot\n",
    "os.makedirs(model_dir + \"/images\", exist_ok=True)\n",
    "fig_forecast.savefig(model_dir + '/images/forecast_plot.png')\n",
    "\n",
    "# Save the forecast components plot\n",
    "fig_components.savefig(model_dir + '/images/forecast_components_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80cb529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Create a new model in the model registry\n",
    "forecast_model = mr.python.create_model(\n",
    "    name=\"waiting_time_forecast_model\",   # Name for the model\n",
    "    metrics=metrics,                      # Metrics used for evaluation\n",
    "    model_schema=model_schema,            # Schema defining the model's input and output\n",
    "    input_example=X_test.sample(),        # Example input data for reference\n",
    "    description=\"Waiting time for a deceased donor kidney transplant forecasting model\",  # Description of the model\n",
    ")\n",
    "\n",
    "# Save the model to the specified directory\n",
    "forecast_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5702f0",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
