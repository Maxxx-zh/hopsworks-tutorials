{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üë®üèª‚Äçüè´ Build Index </span>\n",
    "\n",
    "In this notebook you will create a feature group for your candidate embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/17527\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üéØ Compute Candidate Embeddings </span>\n",
    "\n",
    "You start by computing candidate embeddings for all items in the training data.\n",
    "\n",
    "First, you load your candidate model. Recall that you uploaded it to the Hopsworks Model Registry in the previous notebook. If you don't have the model locally you can download it from the Model Registry using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (2 dirs, 7 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "model = mr.get_model(\n",
    "    name=\"candidate_model\",\n",
    "    version=1,\n",
    ")\n",
    "model_path = model.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have the model saved locally you can simply replace `model_path` with the path to your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_model = tf.saved_model.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you compute the embeddings of all candidate items that were used to train the retrieval model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(\n",
    "    name=\"retrieval\", \n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (221.05s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `2`.\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df, _, _, _ = feature_view.train_validation_test_split(\n",
    "    validation_size=0.1, \n",
    "    test_size=0.1,\n",
    "    description='Retrieval dataset splits',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>t_dat</th>\n",
       "      <th>price</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>age</th>\n",
       "      <th>club_member_status</th>\n",
       "      <th>age_group</th>\n",
       "      <th>garment_group_name</th>\n",
       "      <th>index_group_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d32f22fb2dd1db40ee1bd9e1c214417be617244e8d169e...</td>\n",
       "      <td>663383001</td>\n",
       "      <td>1543190400000</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>32.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>26-35</td>\n",
       "      <td>Jersey Fancy</td>\n",
       "      <td>Baby/Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a111f6bbda7f5e34aa55cc01a94330618e0b8e623ed5b3...</td>\n",
       "      <td>636587016</td>\n",
       "      <td>1543017600000</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>66.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>66+</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Menswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>976b4e7bf5822c869e6638b81bc630350d7c891165b943...</td>\n",
       "      <td>556560005</td>\n",
       "      <td>1540684800000</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>36-45</td>\n",
       "      <td>Trousers Denim</td>\n",
       "      <td>Baby/Children</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id article_id  \\\n",
       "0  d32f22fb2dd1db40ee1bd9e1c214417be617244e8d169e...  663383001   \n",
       "1  a111f6bbda7f5e34aa55cc01a94330618e0b8e623ed5b3...  636587016   \n",
       "2  976b4e7bf5822c869e6638b81bc630350d7c891165b943...  556560005   \n",
       "\n",
       "           t_dat     price  month_sin  month_cos   age club_member_status  \\\n",
       "0  1543190400000  0.030492  -0.500000   0.866025  32.0             ACTIVE   \n",
       "1  1543017600000  0.006763  -0.500000   0.866025  66.0             ACTIVE   \n",
       "2  1540684800000  0.015237  -0.866025   0.500000  44.0             ACTIVE   \n",
       "\n",
       "  age_group garment_group_name index_group_name  \n",
       "0     26-35       Jersey Fancy    Baby/Children  \n",
       "1       66+       Jersey Basic         Menswear  \n",
       "2     36-45     Trousers Denim    Baby/Children  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>garment_group_name</th>\n",
       "      <th>index_group_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>663383001</td>\n",
       "      <td>Jersey Fancy</td>\n",
       "      <td>Baby/Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>636587016</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Menswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>556560005</td>\n",
       "      <td>Trousers Denim</td>\n",
       "      <td>Baby/Children</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id garment_group_name index_group_name\n",
       "0  663383001       Jersey Fancy    Baby/Children\n",
       "1  636587016       Jersey Basic         Menswear\n",
       "2  556560005     Trousers Denim    Baby/Children"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of input features for the candidate model from the model schema\n",
    "model_schema = model.model_schema['input_schema']['columnar_schema']\n",
    "candidate_features = [feat['name'] for feat in model_schema]\n",
    "\n",
    "# Select the candidate features from the training DataFrame\n",
    "item_df = train_df[candidate_features]\n",
    "\n",
    "# Drop duplicate rows based on the 'article_id' column to get unique candidate items\n",
    "item_df.drop_duplicates(subset=\"article_id\", inplace=True)\n",
    "\n",
    "item_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow dataset from the item DataFrame\n",
    "item_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    {col: item_df[col] for col in item_df})\n",
    "\n",
    "# Compute embeddings for all candidate items using the candidate_model\n",
    "candidate_embeddings = item_ds.batch(2048).map(\n",
    "    lambda x: (x[\"article_id\"], candidate_model(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Strictly speaking, you haven't actually computed the candidate embeddings yet, as the dataset functions are lazily evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è Data Preparation </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all article IDs and embeddings from the candidate_embeddings dataset\n",
    "all_article_ids = tf.concat([batch[0] for batch in candidate_embeddings], axis=0)\n",
    "all_embeddings = tf.concat([batch[1] for batch in candidate_embeddings], axis=0)\n",
    "\n",
    "# Convert tensors to numpy arrays\n",
    "all_article_ids_np = all_article_ids.numpy().astype(int)\n",
    "all_embeddings_np = all_embeddings.numpy()\n",
    "\n",
    "# Convert numpy arrays to lists\n",
    "items_ids_list = all_article_ids_np.tolist()\n",
    "embeddings_list = all_embeddings_np.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>663383001</td>\n",
       "      <td>[101.51985931396484, 64.09200286865234, 88.867...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>636587016</td>\n",
       "      <td>[102.14459228515625, 64.44893646240234, 88.727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>556560005</td>\n",
       "      <td>[102.36914825439453, 64.44371032714844, 88.646...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>665851003</td>\n",
       "      <td>[102.3536605834961, 63.86991500854492, 88.8890...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636938001</td>\n",
       "      <td>[102.42069244384766, 63.75370788574219, 88.964...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                         embeddings\n",
       "0   663383001  [101.51985931396484, 64.09200286865234, 88.867...\n",
       "1   636587016  [102.14459228515625, 64.44893646240234, 88.727...\n",
       "2   556560005  [102.36914825439453, 64.44371032714844, 88.646...\n",
       "3   665851003  [102.3536605834961, 63.86991500854492, 88.8890...\n",
       "4   636938001  [102.42069244384766, 63.75370788574219, 88.964..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "data_emb = pd.DataFrame({\n",
    "    'article_id': items_ids_list, \n",
    "    'embeddings': embeddings_list,\n",
    "})\n",
    "\n",
    "data_emb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">ü™Ñ Feature Group Creation </span>\n",
    "\n",
    "Now you are ready to create a feature group for your candidate embeddings.\n",
    "\n",
    "To begin with, you need to create your Embedding Index where you will specify the name of the embeddings feature and the embeddings length.\n",
    "Then you attach this index to the FG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsfs import embedding\n",
    "\n",
    "# Create the Embedding Index\n",
    "emb = embedding.EmbeddingIndex()\n",
    "\n",
    "emb.add_embedding(\n",
    "    \"embeddings\",                           # Embeddings feature name\n",
    "    len(data_emb[\"embeddings\"].iloc[0]),    # Embeddings length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://snurran.hops.works/p/17527/fs/17475/fg/20556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3807c69dccda437f8a6af087863b4b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/42854 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: candidate_embeddings_fg_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://snurran.hops.works/p/17527/jobs/named/candidate_embeddings_fg_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7f1b0f57f6d0>, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get or create the 'candidate_embeddings_fg' feature group\n",
    "candidate_embeddings_fg = fs.get_or_create_feature_group(\n",
    "    name=\"candidate_embeddings_fg\",\n",
    "    embedding_index=emb,                    # Specify the Embedding Index\n",
    "    primary_key=['article_id'],\n",
    "    version=1,\n",
    "    description='Embeddings for each article',\n",
    "    online_enabled=True,\n",
    ")\n",
    "\n",
    "candidate_embeddings_fg.insert(data_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">ü™Ñ Feature View Creation </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://snurran.hops.works/p/17527/fs/17475/fv/candidate_embeddings/version/1\n"
     ]
    }
   ],
   "source": [
    "# Get or create the 'candidate_embeddings' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"candidate_embeddings\",\n",
    "    version=1,\n",
    "    description='Embeddings of each article',\n",
    "    query=candidate_embeddings_fg.select([\"article_id\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27\">‚è©Ô∏è Next Steps </span>\n",
    "\n",
    "At this point you have a recommender system that is able to generate a set of candidate items for a customer. However, many of these could be poor, as the candidate model was trained with only a few subset of the features. In the next notebook, you'll create a ranking dataset to train a *ranking model* to do more fine-grained predictions."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
