{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d8d5c4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Training Pipeline</span>\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\">This notebook explains how to create a feature view, create a training dataset, train a model and save it in the Hopsworks Model Registry.</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "\n",
    "1. Fetch Feature Groups.\n",
    "2. Create a Feature View.\n",
    "3. Create a Training Dataset.\n",
    "4. Train a model.\n",
    "5. Save trained model in the Model Registry.\n",
    "\n",
    "![part2](../../images/02_training-dataset.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e0ed8",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e858f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d834bc",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817cdef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff51a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45881fbc",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üñç Feature View Creation and Retrieval </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab632f1-3928-4528-bcbe-bed67e1f6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data.\n",
    "selected_features = air_quality_fg.select_all().join(\n",
    "    weather_fg.select_except(['city_name', 'unix_time', 'date']), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cf648",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment this if you would like to view your selected features\n",
    "# selected_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c5b7be",
   "metadata": {},
   "source": [
    "`Feature Views` stands between **Feature Groups** and **Training Dataset**. –°ombining **Feature Groups** we can create **Feature Views** which store a metadata of our data. Having **Feature Views** we can create **Training Dataset**.\n",
    "\n",
    "The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "\n",
    "In order to create Feature View we can use `FeatureStore.create_feature_view()` method.\n",
    "\n",
    "You can specify next parameters:\n",
    "\n",
    "- `name` - name of a feature group.\n",
    "\n",
    "- `version` - version of a feature group.\n",
    "\n",
    "- `labels`- our target variable.\n",
    "\n",
    "- `transformation_functions` - functions to transform our features.\n",
    "\n",
    "- `query` - query object with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'air_quality_fv' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='air_quality_fv',\n",
    "    version=1,\n",
    "    query=selected_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f12f3ac",
   "metadata": {},
   "source": [
    "For now, your `Feature View` is saved in Hopsworks and you can retrieve it using `FeatureStore.get_feature_view()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aeb854",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "To create training dataset you use the `FeatureView.training_data()` method.\n",
    "\n",
    "Here are some importand things:\n",
    "\n",
    "- It will inherit the name of FeatureView.\n",
    "\n",
    "- The feature store currently supports the following data formats for\n",
    "training datasets: **tfrecord, csv, tsv, parquet, avro, orc**.\n",
    "\n",
    "- You can choose necessary format using **data_format** parameter.\n",
    "\n",
    "- **start_time** and **end_time** in order to filter dataset in specific time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317668a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = feature_view.training_data(\n",
    "    description = 'Air Quality dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18b3733",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üß¨ Modeling</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c721ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the data in the 'city_name' column\n",
    "label_encoder.fit(X[['city_name']])\n",
    "\n",
    "# Transform the 'city_name' column data using the fitted encoder\n",
    "encoded = label_encoder.transform(X[['city_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a5c8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the output of the label encoding to a dense array and concatenate with the original data\n",
    "X = pd.concat([X, pd.DataFrame(encoded)], axis=1)\n",
    "\n",
    "# Drop columns 'date', 'city_name', 'unix_time' from the DataFrame 'X'\n",
    "X = X.drop(columns=['date', 'city_name', 'unix_time'])\n",
    "\n",
    "# Rename the newly added column with label-encoded city names to 'city_name_encoded'\n",
    "X = X.rename(columns={0: \"city_name_encoded\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ef824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the target variable 'pm2_5' from the DataFrame 'X' and assigning it to the variable 'y'\n",
    "y = X.pop('pm2_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02950e70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets using the train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ddfaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e85ea3",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>üèÉüèª‚Äç‚ôÇÔ∏è Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a6893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the XGBoost Regressor\n",
    "xgb_regressor = XGBRegressor()\n",
    "\n",
    "# Fit the XGBoost Regressor to the training data\n",
    "xgb_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6335331f",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> ‚öñÔ∏è Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bb3d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict target values on the test set\n",
    "y_pred = xgb_regressor.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) using sklearn\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"‚õ≥Ô∏è MSE:\", mse)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) using sklearn\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"‚õ≥Ô∏è RMSE:\", rmse)\n",
    "\n",
    "# Calculate R squared using sklearn\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"‚õ≥Ô∏è R^2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19bd4aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame 'df_' to store true and predicted values for evaluation\n",
    "df_pred = pd.DataFrame({\n",
    "    \"y_true\": y_test,\n",
    "    \"y_pred\": y_pred,\n",
    "})\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bd5801-6749-4206-9ef2-1ae4e6654597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_residual_plot(df_pred):\n",
    "    \"\"\"Create a residual plot with specified styling.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    residplot = sns.residplot(\n",
    "        data=df_pred, \n",
    "        x=\"y_true\", \n",
    "        y=\"y_pred\", \n",
    "        color='orange',\n",
    "        scatter_kws={'alpha': 0.5}\n",
    "    )\n",
    "    \n",
    "    plt.title('Model Residuals', fontsize=14)\n",
    "    plt.xlabel('True Values', fontsize=12)\n",
    "    plt.ylabel('Residuals (Error)', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return residplot.get_figure()\n",
    "\n",
    "def create_feature_importance_plot(xgb_regressor):\n",
    "    \"\"\"Create a feature importance plot with specified styling.\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_importance(\n",
    "        xgb_regressor,\n",
    "        max_num_features=25,\n",
    "        title='Feature Importance',\n",
    "        xlabel='F-score',\n",
    "        ylabel='Features'\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt.gcf()  # get current figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e1a355-e260-47df-b2c9-f7d2d71d423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display plot\n",
    "residual_fig = create_residual_plot(df_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e8684-80b9-421d-9e54-be1d875be782",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_fig = create_feature_importance_plot(xgb_regressor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977f9fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style='color:#ff5f27'>üóÑ Model Registry</span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where you can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd7e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the model registry\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edfa9e0-5229-4d13-9e8b-74e62433c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories and save artifacts\n",
    "model_dir = \"air_quality_model\"\n",
    "images_dir = os.path.join(model_dir, \"images\")\n",
    "os.makedirs(images_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393134d-e4fd-48e8-a3e4-fcff65930054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model artifacts\n",
    "model_artifacts = {\n",
    "    'label_encoder': os.path.join(model_dir, 'label_encoder.pkl'),\n",
    "    'xgboost_model': os.path.join(model_dir, 'xgboost_regressor.pkl')\n",
    "}\n",
    "\n",
    "for name, path in model_artifacts.items():\n",
    "    joblib.dump(\n",
    "        label_encoder if name == 'label_encoder' else xgb_regressor,\n",
    "        path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d26b4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save plots\n",
    "residual_fig.savefig(\n",
    "    os.path.join(images_dir, \"residuals.png\"),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "feature_importance_fig.savefig(\n",
    "    os.path.join(images_dir, \"feature_importance.png\"),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "\n",
    "# Close figures to free memory\n",
    "plt.close(residual_fig)\n",
    "plt.close(feature_importance_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d8166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Python model in the model registry named 'air_quality_xgboost_model'\n",
    "aq_model = mr.python.create_model(\n",
    "    name=\"air_quality_xgboost_model\", \n",
    "    description=\"Air Quality (PM2.5) predictor\",\n",
    "    metrics={\n",
    "        \"RMSE\": rmse,\n",
    "        \"MSE\": mse,\n",
    "        \"R squared\": r2,\n",
    "    },\n",
    "    input_example=X_test.sample().values, \n",
    "    feature_view=feature_view,\n",
    ")\n",
    "\n",
    "# Save the model artifacts to the 'air_quality_model' directory in the model registry\n",
    "aq_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef470a4e",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 04: Batch Inference</span>\n",
    "\n",
    "In the following notebook you will use your model for Batch Inference.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "63265f9757e7c73c149a91832e3b2b12ced37a5390b9151ad08a04f276cd5846"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
