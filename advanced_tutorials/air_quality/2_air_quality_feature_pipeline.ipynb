{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2552d8bf",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Feature Pipeline</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "\n",
    "1. Fetch Feature Groups. \n",
    "2. Parse Data.\n",
    "3. Feature Group Insertion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b231c0db",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf983f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from features import air_quality\n",
    "from functions import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbc36bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Opening the 'target_cities.json' file in read mode using the 'with' statement\n",
    "with open('target_cities.json') as json_file:\n",
    "    # Loading the JSON data from the file and storing it in the 'target_cities' variable\n",
    "    target_cities = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07e46c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(2024, 2, 23), '2024-02-23')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the current date\n",
    "today = datetime.date.today()\n",
    "\n",
    "# Displaying the current date and its string representation\n",
    "today, str(today)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e64602",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06651b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5242\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a6f5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640ab38b",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå´ Filling gaps in Air Quality data (PM2.5)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edc5510b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (3.26s) \n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (2.25s) \n"
     ]
    }
   ],
   "source": [
    "# Read data from feature groups\n",
    "df_air_quality = air_quality_fg.read()\n",
    "df_weather = weather_fg.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb667b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting the \"date\" and \"city_name\" columns from the 'df_air_quality' DataFrame\n",
    "# Grouping the data by \"city_name\" and finding the maximum date for each city\n",
    "last_dates_aq = df_air_quality[[\"date\", \"city_name\"]].groupby(\"city_name\").max()\n",
    "\n",
    "# Converting the date values to string format for consistency\n",
    "last_dates_aq.date = last_dates_aq.date.astype(str)\n",
    "\n",
    "# Creating a dictionary with city names as keys and their corresponding last updated date as values\n",
    "last_dates_aq = last_dates_aq.to_dict()[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74862993",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õ≥Ô∏è Last update for Paris: 2024-02-23\n",
      "‚õ≥Ô∏è Last update for Columbus: 2024-02-23\n"
     ]
    }
   ],
   "source": [
    "# Accessing the last updated date for the city of Paris\n",
    "paris_last_date = last_dates_aq.get(\"Paris\", \"Not available\")\n",
    "\n",
    "# Accessing the last updated date for the city of Columbus\n",
    "columbus_last_date = last_dates_aq.get(\"Columbus\", \"Not available\")\n",
    "\n",
    "# Printing the results\n",
    "print(\"‚õ≥Ô∏è Last update for Paris:\", paris_last_date)\n",
    "print(\"‚õ≥Ô∏è Last update for Columbus:\", columbus_last_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7790102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for city, date in last_dates_aq.items():\n",
    "    city_last_date = datetime.datetime.strptime(date, \"%Y-%m-%d\").date()\n",
    "    if (today - city_last_date) <= datetime.timedelta(days=28):\n",
    "        last_dates_aq[city] = (city_last_date - datetime.timedelta(days=28)).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fd48eb",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'>  üßôüèº‚Äç‚ôÇÔ∏è Parsing PM2.5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed8324e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed PM2_5 for Amsterdam since 2024-01-26 till 2024-02-23.\n",
      "Took 0.12 sec.\n",
      "\n",
      "Processed PM2_5 for Athina since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for Berlin since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for Gdansk since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for Krak√≥w since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for London since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for Madrid since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for Marseille since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for Milano since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for M√ºnchen since 2024-01-26 till 2024-02-23.\n",
      "Took 0.16 sec.\n",
      "\n",
      "Processed PM2_5 for Napoli since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for Paris since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for Sevilla since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for Stockholm since 2024-01-26 till 2024-02-23.\n",
      "Took 0.12 sec.\n",
      "\n",
      "Processed PM2_5 for Tallinn since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for Varna since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for Wien since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for Albuquerque since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for Atlanta since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for Chicago since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for Columbus since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for Dallas since 2024-01-26 till 2024-02-23.\n",
      "Took 0.14 sec.\n",
      "\n",
      "Processed PM2_5 for Denver since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for Houston since 2024-01-26 till 2024-02-23.\n",
      "Took 0.14 sec.\n",
      "\n",
      "Processed PM2_5 for Los Angeles since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for New York since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for Phoenix-Mesa since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for Salt Lake City since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for San Francisco since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for Tampa since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for Bellevue-SE 12th St since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for DARRINGTON - FIR ST (Darrington High School) since 2024-01-26 till 2024-02-23.\n",
      "Took 0.17 sec.\n",
      "\n",
      "Processed PM2_5 for KENT - JAMES & CENTRAL since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for LAKE FOREST PARK TOWNE CENTER since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for MARYSVILLE - 7TH AVE (Marysville Junior High) since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for NORTH BEND - NORTH BEND WAY since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for SEATTLE - BEACON HILL since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for SEATTLE - DUWAMISH since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for SEATTLE - SOUTH PARK #2 since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for Seattle-10th & Weller since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for TACOMA - ALEXANDER AVE since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for TACOMA - L STREET since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for Tacoma-S 36th St since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "Processed PM2_5 for Tukwila Allentown since 2024-01-26 till 2024-02-23.\n",
      "Took 0.11 sec.\n",
      "\n",
      "Processed PM2_5 for Tulalip-Totem Beach Rd since 2024-01-26 till 2024-02-23.\n",
      "Took 0.1 sec.\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Parsed new PM2.5 data for ALL locations up to 2024-02-23.\n",
      "Took 5.04 sec.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Storing the current time as the start time of the cell execution\n",
    "start_of_cell = time.time()\n",
    "\n",
    "# Creating an empty DataFrame to store raw air quality data\n",
    "df_aq_raw = pd.DataFrame()\n",
    "\n",
    "# Iterating through continents and cities in the 'target_cities' dictionary\n",
    "for continent in target_cities:\n",
    "    for city_name, coords in target_cities[continent].items():\n",
    "        # Retrieving air quality data using the 'get_aqi_data_from_open_meteo' function\n",
    "        # with specified parameters such as city name, coordinates, start date, and end date\n",
    "        df_ = get_aqi_data_from_open_meteo(\n",
    "            city_name=city_name,\n",
    "            coordinates=coords,\n",
    "            start_date=last_dates_aq[city_name],\n",
    "            end_date=str(today)\n",
    "        )\n",
    "        \n",
    "        # Concatenating the retrieved data with the existing 'df_aq_raw' DataFrame\n",
    "        # and resetting the index to ensure proper alignment\n",
    "        df_aq_raw = pd.concat([df_aq_raw, df_]).reset_index(drop=True)\n",
    "\n",
    "# Storing the current time as the end time of the cell execution\n",
    "end_of_cell = time.time()\n",
    "\n",
    "# Printing information about the execution, including the time taken\n",
    "print(\"-\" * 64)\n",
    "print(f\"Parsed new PM2.5 data for ALL locations up to {str(today)}.\")\n",
    "print(f\"Took {round(end_of_cell - start_of_cell, 2)} sec.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c47cfcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>date</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>Tulalip-Totem Beach Rd</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>Tulalip-Totem Beach Rd</td>\n",
       "      <td>2024-02-22</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Tulalip-Totem Beach Rd</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   city_name        date  pm2_5\n",
       "1302  Tulalip-Totem Beach Rd  2024-02-21    8.4\n",
       "1303  Tulalip-Totem Beach Rd  2024-02-22    3.4\n",
       "1304  Tulalip-Totem Beach Rd  2024-02-23    8.7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aq_raw.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9054f8d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#ff5f27;\">üõ† Feature Engineering PM2.5</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc1b957c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting the 'date' column in the 'df_aq_update' DataFrame to datetime format\n",
    "df_aq_raw['date'] = pd.to_datetime(df_aq_raw['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be43a5b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>date</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>pm_2_5_previous_1_day</th>\n",
       "      <th>pm_2_5_previous_2_day</th>\n",
       "      <th>pm_2_5_previous_3_day</th>\n",
       "      <th>pm_2_5_previous_4_day</th>\n",
       "      <th>pm_2_5_previous_5_day</th>\n",
       "      <th>pm_2_5_previous_6_day</th>\n",
       "      <th>pm_2_5_previous_7_day</th>\n",
       "      <th>...</th>\n",
       "      <th>exp_std_28_days</th>\n",
       "      <th>year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>sin_day_of_year</th>\n",
       "      <th>cos_day_of_year</th>\n",
       "      <th>sin_day_of_week</th>\n",
       "      <th>cos_day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>Krak√≥w</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>22.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>23.8</td>\n",
       "      <td>19.2</td>\n",
       "      <td>26.7</td>\n",
       "      <td>27.7</td>\n",
       "      <td>26.2</td>\n",
       "      <td>65.4</td>\n",
       "      <td>...</td>\n",
       "      <td>17.511933</td>\n",
       "      <td>2024</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801361</td>\n",
       "      <td>0.598181</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>Columbus</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>23.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>22.8</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>...</td>\n",
       "      <td>5.525128</td>\n",
       "      <td>2024</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801361</td>\n",
       "      <td>0.598181</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Milano</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>24.4</td>\n",
       "      <td>49.2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>79.5</td>\n",
       "      <td>92.2</td>\n",
       "      <td>119.4</td>\n",
       "      <td>114.2</td>\n",
       "      <td>110.1</td>\n",
       "      <td>...</td>\n",
       "      <td>31.152944</td>\n",
       "      <td>2024</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801361</td>\n",
       "      <td>0.598181</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     city_name       date  pm2_5  pm_2_5_previous_1_day  \\\n",
       "1302    Krak√≥w 2024-02-23   22.2                   18.7   \n",
       "1303  Columbus 2024-02-23   23.3                   17.0   \n",
       "1304    Milano 2024-02-23   24.4                   49.2   \n",
       "\n",
       "      pm_2_5_previous_2_day  pm_2_5_previous_3_day  pm_2_5_previous_4_day  \\\n",
       "1302                   23.8                   19.2                   26.7   \n",
       "1303                   10.3                   22.8                   17.8   \n",
       "1304                   62.8                   79.5                   92.2   \n",
       "\n",
       "      pm_2_5_previous_5_day  pm_2_5_previous_6_day  pm_2_5_previous_7_day  \\\n",
       "1302                   27.7                   26.2                   65.4   \n",
       "1303                    9.5                    5.6                    5.8   \n",
       "1304                  119.4                  114.2                  110.1   \n",
       "\n",
       "      ...  exp_std_28_days  year  day_of_month  month  day_of_week  \\\n",
       "1302  ...        17.511933  2024            23      2            4   \n",
       "1303  ...         5.525128  2024            23      2            4   \n",
       "1304  ...        31.152944  2024            23      2            4   \n",
       "\n",
       "      is_weekend  sin_day_of_year  cos_day_of_year  sin_day_of_week  \\\n",
       "1302           0         0.801361         0.598181        -0.433884   \n",
       "1303           0         0.801361         0.598181        -0.433884   \n",
       "1304           0         0.801361         0.598181        -0.433884   \n",
       "\n",
       "      cos_day_of_week  \n",
       "1302        -0.900969  \n",
       "1303        -0.900969  \n",
       "1304        -0.900969  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying a feature engineering function 'feature_engineer_aq' to the 'df_aq_update' DataFrame\n",
    "df_aq_update = air_quality.feature_engineer_aq(df_aq_raw)\n",
    "\n",
    "# Dropping rows with missing values in the 'df_aq_update' DataFrame\n",
    "df_aq_update = df_aq_update.dropna()\n",
    "\n",
    "df_aq_update.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b046956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the total number of missing values in the 'df_aq_update' DataFrame\n",
    "df_aq_update.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ae477ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 31)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the dimensions (number of rows and columns) of the 'df_aq_update' DataFrame\n",
    "df_aq_update.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f33e25",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Filling gaps in Weather data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32eeb729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting the \"date\" and \"city_name\" columns from the 'df_weather' DataFrame\n",
    "# Grouping the data by \"city_name\" and finding the maximum date for each city\n",
    "last_dates_weather = df_weather[[\"date\", \"city_name\"]].groupby(\"city_name\").max()\n",
    "\n",
    "# Converting the date values to string format for consistency\n",
    "last_dates_weather.date = last_dates_weather.date.astype(str)\n",
    "\n",
    "# Creating a dictionary with city names as keys and their corresponding last updated date as values\n",
    "last_dates_weather = last_dates_weather.to_dict()[\"date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb144e4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style='color:#ff5f27'>  üßôüèº‚Äç‚ôÇÔ∏è Parsing Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ed0d92c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed weather for Amsterdam since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Athina since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Berlin since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Gdansk since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for Krak√≥w since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for London since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Madrid since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for Marseille since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Milano since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for M√ºnchen since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for Napoli since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Paris since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Sevilla since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Stockholm since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Tallinn since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for Varna since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for Wien since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Albuquerque since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Atlanta since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Chicago since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Columbus since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for Dallas since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Denver since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for Houston since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for Los Angeles since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for New York since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Phoenix-Mesa since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Salt Lake City since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for San Francisco since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Tampa since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for Bellevue-SE 12th St since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for DARRINGTON - FIR ST (Darrington High School) since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for KENT - JAMES & CENTRAL since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for LAKE FOREST PARK TOWNE CENTER since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for MARYSVILLE - 7TH AVE (Marysville Junior High) since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for NORTH BEND - NORTH BEND WAY since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for SEATTLE - BEACON HILL since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for SEATTLE - DUWAMISH since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for SEATTLE - SOUTH PARK #2 since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Seattle-10th & Weller since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for TACOMA - ALEXANDER AVE since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for TACOMA - L STREET since 2024-02-23 till 2024-02-23.\n",
      "Took 2.11 sec.\n",
      "\n",
      "Parsed weather for Tacoma-S 36th St since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Tukwila Allentown since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "Parsed weather for Tulalip-Totem Beach Rd since 2024-02-23 till 2024-02-23.\n",
      "Took 2.1 sec.\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Parsed new weather data for ALL cities up to 2024-02-23.\n",
      "Took 94.76 sec.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Storing the current time as the start time of the cell execution\n",
    "start_of_cell = time.time()\n",
    "\n",
    "# Creating an empty DataFrame to store raw weather data\n",
    "df_weather_update = pd.DataFrame()\n",
    "\n",
    "# Iterating through continents and cities in the 'target_cities' dictionary\n",
    "for continent in target_cities:\n",
    "    for city_name, coords in target_cities[continent].items():\n",
    "        # Retrieving weather data using the 'get_weather_data_from_open_meteo' function\n",
    "        # with specified parameters such as city name, coordinates, start date, end date, and forecast flag\n",
    "        df_ = get_weather_data_from_open_meteo(\n",
    "            city_name=city_name,\n",
    "            coordinates=coords,\n",
    "            start_date=last_dates_weather[city_name],\n",
    "            end_date=str(today),\n",
    "            forecast=True,\n",
    "        )\n",
    "        \n",
    "        # Concatenating the retrieved data with the existing 'df_weather_update' DataFrame\n",
    "        # and resetting the index to ensure proper alignment\n",
    "        df_weather_update = pd.concat([df_weather_update, df_]).reset_index(drop=True)\n",
    "\n",
    "# Dropping rows with missing values in the 'df_weather_update' DataFrame\n",
    "df_weather_update.dropna(inplace=True)\n",
    "\n",
    "# Storing the current time as the end time of the cell execution\n",
    "end_of_cell = time.time()\n",
    "\n",
    "# Printing information about the execution, including the time taken\n",
    "print(\"-\" * 64)\n",
    "print(f\"Parsed new weather data for ALL cities up to {str(today)}.\")\n",
    "print(f\"Took {round(end_of_cell - start_of_cell, 2)} sec.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a149c4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting the 'date' column in the 'df_aq_update' DataFrame to datetime format\n",
    "df_aq_update.date = pd.to_datetime(df_aq_update.date)\n",
    "\n",
    "# Converting the 'date' column in the 'df_weather_update' DataFrame to datetime format\n",
    "df_weather_update.date = pd.to_datetime(df_weather_update.date)\n",
    "\n",
    "# Creating a new column 'unix_time' in 'df_aq_update' by applying the 'convert_date_to_unix' function\n",
    "df_aq_update[\"unix_time\"] = df_aq_update[\"date\"].apply(convert_date_to_unix)\n",
    "\n",
    "# Creating a new column 'unix_time' in 'df_weather_update' by applying the 'convert_date_to_unix' function\n",
    "df_weather_update[\"unix_time\"] = df_weather_update[\"date\"].apply(convert_date_to_unix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7960e1b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_max</th>\n",
       "      <th>temperature_min</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>snowfall_sum</th>\n",
       "      <th>precipitation_hours</th>\n",
       "      <th>wind_speed_max</th>\n",
       "      <th>wind_gusts_max</th>\n",
       "      <th>wind_direction_dominant</th>\n",
       "      <th>unix_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tacoma-S 36th St</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1708646400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Tukwila Allentown</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>13.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>329</td>\n",
       "      <td>1708646400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Tulalip-Totem Beach Rd</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>11.5</td>\n",
       "      <td>357</td>\n",
       "      <td>1708646400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 city_name        date  temperature_max  temperature_min  \\\n",
       "42        Tacoma-S 36th St  2024-02-23             12.1              2.8   \n",
       "43       Tukwila Allentown  2024-02-23             13.2              3.3   \n",
       "44  Tulalip-Totem Beach Rd  2024-02-23             12.7              3.7   \n",
       "\n",
       "    precipitation_sum  rain_sum  snowfall_sum  precipitation_hours  \\\n",
       "42                0.0       0.0           0.0                  0.0   \n",
       "43                0.0       0.0           0.0                  0.0   \n",
       "44                0.0       0.0           0.0                  0.0   \n",
       "\n",
       "    wind_speed_max  wind_gusts_max  wind_direction_dominant      unix_time  \n",
       "42             8.0            12.2                        5  1708646400000  \n",
       "43             6.3            12.6                      329  1708646400000  \n",
       "44             7.9            11.5                      357  1708646400000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the 'date' column in the 'df_aq_update' DataFrame to string format\n",
    "df_aq_update.date = df_aq_update.date.astype(str)\n",
    "\n",
    "# Converting the 'wind_direction_dominant' column in the 'df_weather_update' DataFrame to integer format\n",
    "df_weather_update.wind_direction_dominant = df_weather_update.wind_direction_dominant.astype('int')\n",
    "\n",
    "# Converting the 'date' column in the 'df_weather_update' DataFrame to string format\n",
    "df_weather_update.date = df_weather_update.date.astype(str)\n",
    "df_weather_update.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1db92",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27;\">‚¨ÜÔ∏è Uploading new data to the Feature Store</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "403a8f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13836ef8e3384504b27063ea496c122f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/45 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://snurran.hops.works/p/5242/jobs/named/air_quality_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7fcb00539a50>, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert new data\n",
    "air_quality_fg.insert(df_aq_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc2cb1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01811207264a4dc8a78130e301d43f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/45 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://snurran.hops.works/p/5242/jobs/named/weather_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7fcb00538c70>, None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert new data\n",
    "weather_fg.insert(df_weather_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309617db",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 03: Training Pipeline\n",
    " </span> \n",
    "\n",
    "In the following notebook you will create a feature view, create a training dataset, train a model and save it in the Hopsworks Model Registry."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "190ea7959a836f4799545ea0f3718ade3abee093b15861ffdc25233d6ab7050e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
