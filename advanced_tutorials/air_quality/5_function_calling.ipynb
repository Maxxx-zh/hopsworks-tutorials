{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee392cdb",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89ab053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ef71c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "import joblib\n",
    "import inspect\n",
    "import json\n",
    "from typing import get_type_hints\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a870a7",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4b907de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5242\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc6094c",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Feature View Retrieval</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb6ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the 'air_quality_fv' feature view\n",
    "feature_view = fs.get_feature_view(\n",
    "    name='air_quality_fv',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# Initialize batch scoring\n",
    "feature_view.init_batch_scoring(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa9b97",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">ü™ù Retrieve model from Model Registry</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd7b9905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Downloading model artifact (0 dirs, 6 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "# Retrieve the model registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Retrieve the 'air_quality_xgboost_model' from the model registry\n",
    "retrieved_model = mr.get_model(\n",
    "    name=\"air_quality_xgboost_model\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# Download the saved model artifacts to a local directory\n",
    "saved_model_dir = retrieved_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20cb0255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the XGBoost regressor model and label encoder from the saved model directory\n",
    "model_air_quality = joblib.load(saved_model_dir + \"/xgboost_regressor.pkl\")\n",
    "encoder = joblib.load(saved_model_dir + \"/label_encoder.pkl\")\n",
    "\n",
    "# Display the retrieved XGBoost regressor model\n",
    "model_air_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f0db7",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üóÑÔ∏è Functions</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98381fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data, encoder):\n",
    "    \"\"\"\n",
    "    Transform the input data by encoding the 'city_name' column and dropping unnecessary columns.\n",
    "    \n",
    "    Args:\n",
    "    - data (DataFrame): Input data to be transformed.\n",
    "    - encoder (LabelEncoder): Label encoder object to encode 'city_name'.\n",
    "    \n",
    "    Returns:\n",
    "    - data_transformed (DataFrame): Transformed data with 'city_name_encoded' and dropped columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy of the input data to avoid modifying the original data\n",
    "    data_transformed = data.copy()\n",
    "    \n",
    "    # Transform the 'city_name' column in the batch data using the retrieved label encoder\n",
    "    data_transformed['city_name_encoded'] = encoder.transform(data_transformed['city_name'])\n",
    "    \n",
    "    # Drop unnecessary columns from the batch data\n",
    "    data_transformed = data_transformed.drop(columns=['unix_time', 'pm2_5', 'city_name', 'date'])\n",
    "\n",
    "    return data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcfecdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "def get_data_for_date(date: str, city_name: str, feature_view, model) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve data for a specific date and city from a feature view.\n",
    "\n",
    "    Args:\n",
    "        date (str): The date in the format \"%Y-%m-%d\".\n",
    "        city_name (str): The name of the city to retrieve data for.\n",
    "        feature_view: The feature view object.\n",
    "        model: The machine learning model used for prediction.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing data for the specified date and city.\n",
    "    \"\"\"\n",
    "    # Convert date string to datetime object\n",
    "    date_datetime = datetime.datetime.strptime(date, \"%Y-%m-%d\").date()\n",
    "    \n",
    "    # Retrieve batch data for the specified date range\n",
    "    batch_data = feature_view.get_batch_data(\n",
    "        start_time=date_datetime,\n",
    "        end_time=date_datetime + datetime.timedelta(days=1),\n",
    "    )\n",
    "    \n",
    "    # Filter batch data for the specified city\n",
    "    batch_data_filtered = batch_data[batch_data['city_name'] == city_name]\n",
    "    \n",
    "    return batch_data_filtered[['date', 'pm2_5']].sort_values('date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abd770b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_in_date_range(date_start: str, date_end: str, city_name: str, feature_view, model) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve data for a specific date range and city from a feature view.\n",
    "\n",
    "    Args:\n",
    "        date_start (str): The start date in the format \"%Y-%m-%d\".\n",
    "        date_end (str): The end date in the format \"%Y-%m-%d\".\n",
    "        city_name (str): The name of the city to retrieve data for.\n",
    "        feature_view: The feature view object.\n",
    "        model: The machine learning model used for prediction.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing data for the specified date range and city.\n",
    "    \"\"\"\n",
    "    # Convert date strings to datetime objects\n",
    "    date_start_dt = datetime.datetime.strptime(date_start, \"%Y-%m-%d\").date()\n",
    "    date_end_dt = datetime.datetime.strptime(date_end, \"%Y-%m-%d\").date()\n",
    "    \n",
    "    # Retrieve batch data for the specified date range\n",
    "    batch_data = feature_view.get_batch_data(\n",
    "        start_time=date_start_dt,\n",
    "        end_time=date_end_dt + datetime.timedelta(days=1),\n",
    "    )\n",
    "\n",
    "    # Filter batch data for the specified city\n",
    "    batch_data_filtered = batch_data[batch_data['city_name'] == city_name]\n",
    "    \n",
    "    return batch_data_filtered[['date', 'pm2_5']].sort_values('date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73f9937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def get_future_data(date: str, city_name: str, feature_view, model) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Predicts future PM2.5 data for a specified date and city using a given feature view and model.\n",
    "\n",
    "    Args:\n",
    "        date (str): The target future date in the format 'YYYY-MM-DD'.\n",
    "        city_name (str): The name of the city for which the prediction is made.\n",
    "        feature_view: The feature view used to retrieve batch data.\n",
    "        model: The machine learning model used for prediction.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing predicted PM2.5 values for each day starting from the target date.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get today's date\n",
    "    today = datetime.date.today()\n",
    "\n",
    "    # Convert the target date string to a datetime object\n",
    "    date_in_future = datetime.datetime.strptime(date, \"%Y-%m-%d\").date()\n",
    "\n",
    "    # Calculate the difference in days between today and the target date\n",
    "    difference_in_days = (date_in_future - today).days\n",
    "\n",
    "    # Retrieve batch data for the specified date range\n",
    "    batch_data = feature_view.get_batch_data(\n",
    "        start_time=today,\n",
    "        end_time=today + datetime.timedelta(days=1),\n",
    "    )\n",
    "    \n",
    "    # Filter batch data for the specified city\n",
    "    batch_data_filtered = batch_data[batch_data['city_name'] == city_name]\n",
    "        \n",
    "    # Transform batch data\n",
    "    batch_data_transformed = transform_data(batch_data_filtered, encoder)\n",
    "    \n",
    "    # Initialize a DataFrame to store predicted PM2.5 values\n",
    "    predicted_pm2_5_df = pd.DataFrame({\n",
    "        'date': [today.strftime(\"%Y-%m-%d\")], \n",
    "        'pm2_5': batch_data_filtered['pm2_5'].values[0],\n",
    "    })\n",
    "\n",
    "    # Iterate through each day starting from tomorrow up to the target date\n",
    "    for day_number in range(1, difference_in_days + 1):\n",
    "\n",
    "        # Calculate the date for the current future day\n",
    "        date_future_day = (today + datetime.timedelta(days=day_number)).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        # Predict PM2.5 for the current day\n",
    "        predicted_pm2_5 = model.predict(batch_data_transformed)\n",
    "\n",
    "        # Update previous day PM2.5 values in the batch data for the next prediction\n",
    "        batch_data_transformed['pm_2_5_previous_7_day'] = batch_data_transformed['pm_2_5_previous_6_day']\n",
    "        batch_data_transformed['pm_2_5_previous_6_day'] = batch_data_transformed['pm_2_5_previous_5_day']\n",
    "        batch_data_transformed['pm_2_5_previous_5_day'] = batch_data_transformed['pm_2_5_previous_4_day']\n",
    "        batch_data_transformed['pm_2_5_previous_4_day'] = batch_data_transformed['pm_2_5_previous_3_day']\n",
    "        batch_data_transformed['pm_2_5_previous_3_day'] = batch_data_transformed['pm_2_5_previous_2_day']\n",
    "        batch_data_transformed['pm_2_5_previous_2_day'] = batch_data_transformed['pm_2_5_previous_1_day']\n",
    "        batch_data_transformed['pm_2_5_previous_1_day'] = predicted_pm2_5\n",
    "        \n",
    "        # Append the predicted PM2.5 value for the current day to the DataFrame\n",
    "        predicted_pm2_5_df = predicted_pm2_5_df._append({\n",
    "            'date': date_future_day, \n",
    "            'pm2_5': predicted_pm2_5[0],\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "    return predicted_pm2_5_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dd29714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (7.54s) \n",
      "‚õ≥Ô∏è 2024-01-10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-10</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  pm2_5\n",
       "0  2024-01-10   20.3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_date = get_data_for_date(\n",
    "    '2024-01-10', \n",
    "    'Paris',\n",
    "    feature_view,\n",
    "    model_air_quality,\n",
    ")\n",
    "print(f'‚õ≥Ô∏è {data_for_date.date.max()}')\n",
    "data_for_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b353d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (7.52s) \n",
      "‚õ≥Ô∏è ('2024-01-10', '2024-01-20')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-10</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-13</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  pm2_5\n",
       "0  2024-01-10   11.7\n",
       "1  2024-01-11   15.2\n",
       "2  2024-01-12   12.1\n",
       "3  2024-01-13    5.4\n",
       "4  2024-01-14    3.8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in_range = get_data_in_date_range(\n",
    "    '2024-01-10', \n",
    "    '2024-01-20', \n",
    "    'Amsterdam',\n",
    "    feature_view,\n",
    "    model_air_quality,\n",
    ")\n",
    "print(f'‚õ≥Ô∏è {data_in_range.date.min(), data_in_range.date.max()}')\n",
    "data_in_range.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e896081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (7.50s) \n",
      "‚õ≥Ô∏è ('2024-02-23', '2024-02-25')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>8.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>7.449322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-25</td>\n",
       "      <td>8.308480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     pm2_5\n",
       "0  2024-02-23  8.100000\n",
       "1  2024-02-24  7.449322\n",
       "2  2024-02-25  8.308480"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_future = get_future_data(\n",
    "    '2024-02-25', \n",
    "    'London',\n",
    "    feature_view,\n",
    "    model_air_quality,\n",
    ")\n",
    "print(f'‚õ≥Ô∏è {data_future.date.min(), data_future.date.max()}')\n",
    "data_future.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea7055",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>‚¨áÔ∏è Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f817eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name: str):\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    with torch.device(\"cuda:0\"):\n",
    "        model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "            model_name, \n",
    "            torch_dtype=torch.bfloat16,\n",
    "        ).eval()\n",
    "    \n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d21b4f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd409643efb4d7cbe4022f55d06626c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"teknium/OpenHermes-2.5-Mistral-7B\"\n",
    "\n",
    "tokenizer, model_llm = load_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3c97a7",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>‚öôÔ∏è Tools </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12607b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_name(t):\n",
    "    name = str(t)\n",
    "    if \"list\" in name or \"dict\" in name:\n",
    "        return name\n",
    "    else:\n",
    "        return t.__name__\n",
    "\n",
    "def serialize_function_to_json(func):\n",
    "    signature = inspect.signature(func)\n",
    "    type_hints = get_type_hints(func)\n",
    "\n",
    "    function_info = {\n",
    "        \"name\": func.__name__,\n",
    "        \"description\": func.__doc__,\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {}\n",
    "        },\n",
    "        \"returns\": type_hints.get('return', 'void').__name__\n",
    "    }\n",
    "\n",
    "    for name, _ in signature.parameters.items():\n",
    "        param_type = get_type_name(type_hints.get(name, type(None)))\n",
    "        function_info[\"parameters\"][\"properties\"][name] = {\"type\": param_type}\n",
    "\n",
    "    return json.dumps(function_info, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fb4bad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"get_data_in_date_range\",\n",
      "  \"description\": \"\\n    Retrieve data for a specific date range and city from a feature view.\\n\\n    Args:\\n        date_start (str): The start date in the format \\\"%Y-%m-%d\\\".\\n        date_end (str): The end date in the format \\\"%Y-%m-%d\\\".\\n        city_name (str): The name of the city to retrieve data for.\\n        feature_view: The feature view object.\\n        model: The machine learning model used for prediction.\\n\\n    Returns:\\n        pd.DataFrame: A DataFrame containing data for the specified date range and city.\\n    \",\n",
      "  \"parameters\": {\n",
      "    \"type\": \"object\",\n",
      "    \"properties\": {\n",
      "      \"date_start\": {\n",
      "        \"type\": \"str\"\n",
      "      },\n",
      "      \"date_end\": {\n",
      "        \"type\": \"str\"\n",
      "      },\n",
      "      \"city_name\": {\n",
      "        \"type\": \"str\"\n",
      "      },\n",
      "      \"feature_view\": {\n",
      "        \"type\": \"NoneType\"\n",
      "      },\n",
      "      \"model\": {\n",
      "        \"type\": \"NoneType\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"returns\": \"DataFrame\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(serialize_function_to_json(get_data_in_date_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4cfe49",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>üîÆ Function Matching </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a47290ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "def extract_function_calls(completion):\n",
    "    completion = completion.strip()\n",
    "    pattern = r\"(<multiplefunctions>(.*?)</multiplefunctions>)\"\n",
    "    match = re.search(pattern, completion, re.DOTALL)\n",
    "    if not match:\n",
    "        return None\n",
    "    \n",
    "    multiplefn = match.group(1)\n",
    "    root = ET.fromstring(multiplefn)\n",
    "    functions = root.findall(\"functioncall\")\n",
    "    return [json.loads(fn.text) for fn in functions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "501cb2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hermes(prompt, model_llm, tokenizer):\n",
    "    fn = \"\"\"{\"name\": \"function_name\", \"arguments\": {\"arg_1\": \"value_1\", \"arg_2\": value_2, ...}}\"\"\"\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "You are a helpful assistant with access to the following functions:\n",
    "\n",
    "{serialize_function_to_json(get_data_for_date)}\n",
    "\n",
    "{serialize_function_to_json(get_data_in_date_range)}\n",
    "\n",
    "{serialize_function_to_json(get_future_data)}\n",
    "\n",
    "You need to choose what function to use and retrieve paramenters for this function from the user input.\n",
    "IMPORTANT: Today is {datetime.date.today().strftime(\"%A\")}, {datetime.date.today()}.\n",
    "IMPORTANT: If the user query contains 'will', it is very likely that you will need to use the get_future_data function\n",
    "NOTE: Ignore the Feature View and Model parameters.\n",
    "NOTE: Dates should be provided in the format YYYY-MM-DD.\n",
    "\n",
    "To use these functions respond with:\n",
    "<multiplefunctions>\n",
    "    <functioncall> {fn} </functioncall>\n",
    "    <functioncall> {fn} </functioncall>\n",
    "    ...\n",
    "</multiplefunctions>\n",
    "\n",
    "Edge cases you must handle:\n",
    "- If there are no functions that match the user request, you will respond politely that you cannot help.<|im_end|>\n",
    "<|im_start|>user\n",
    "{prompt}<|im_end|>\n",
    "<|im_start|>assistant\"\"\"\n",
    "    \n",
    "    tokens = tokenizer(prompt, return_tensors=\"pt\").to(model_llm.device)\n",
    "    input_size = tokens.input_ids.numel()\n",
    "    with torch.inference_mode():\n",
    "        generated_tokens = model_llm.generate(\n",
    "            **tokens, \n",
    "            use_cache=True, \n",
    "            do_sample=True, \n",
    "            temperature=0.2, \n",
    "            top_p=1.0, \n",
    "            top_k=0, \n",
    "            max_new_tokens=512, \n",
    "            eos_token_id=tokenizer.eos_token_id, \n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(\n",
    "        generated_tokens.squeeze()[input_size:], \n",
    "        skip_special_tokens=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6c0c4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a helpful assistant designed to retrieve data related to air pollution. How can I help you with that?\n",
      "====================================================================================================\n",
      "[{'name': 'get_data_for_date', 'arguments': {'date': '2024-02-23', 'city_name': 'Paris'}}]\n",
      "====================================================================================================\n",
      "[{'name': 'get_data_for_date', 'arguments': {'date': '2024-02-22', 'city_name': 'New York'}}]\n",
      "====================================================================================================\n",
      "[{'name': 'get_data_in_date_range', 'arguments': {'date_start': '2024-01-10', 'date_end': '2024-01-14', 'city_name': 'London'}}]\n",
      "====================================================================================================\n",
      "[{'name': 'get_future_data', 'arguments': {'date': '2024-02-26', 'city_name': 'London'}}]\n",
      "====================================================================================================\n",
      "[{'name': 'get_future_data', 'arguments': {'date': '2024-02-25', 'city_name': 'London'}}]\n",
      "====================================================================================================\n",
      "[{'name': 'get_future_data', 'arguments': {'date': '2024-03-01', 'city_name': 'London'}}]\n",
      "====================================================================================================\n",
      "[{'name': 'get_future_data', 'arguments': {'date': '2024-03-01', 'city_name': 'Amsterdam'}}]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"How are you?\",\n",
    "    \"What's the air quality today in Paris?\",\n",
    "    \"What was the air quality yesterday in New York?\",\n",
    "    \"What was the air quality from 2024-01-10 till 2024-01-14 in London?\",\n",
    "    \"What will the air quality be like in London in 2024-02-26?\",\n",
    "    \"What will the air quality be like in London the day after tomorrow?\",\n",
    "    \"What will the air quality be like in London next Friday?\",\n",
    "    \"What will the air quality be like on March 1 in Amsterdam?\",\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    completion = generate_hermes(prompt, model_llm, tokenizer)\n",
    "    functions = extract_function_calls(completion)\n",
    "\n",
    "    if functions:\n",
    "        print(functions)\n",
    "    else:\n",
    "        print(completion.strip())\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd2d41b",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>üöÄ Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8318c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_function(function, feature_view, model):\n",
    "    # Extract function name and arguments from input_data\n",
    "    function_name = function['name']\n",
    "    arguments = function['arguments']\n",
    "    \n",
    "    # Using Python's getattr function to dynamically call the function by its name and passing the arguments\n",
    "    function_output = getattr(sys.modules[__name__], function_name)(**arguments, feature_view=feature_view, model=model)\n",
    "    \n",
    "    # Round the 'pm2_5' value to 2 decimal places\n",
    "    function_output['pm2_5'] = function_output['pm2_5'].apply(round, ndigits=2)\n",
    "    return function_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1921e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_future_data',\n",
       "  'arguments': {'date': '2024-03-01', 'city_name': 'Amsterdam'}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff8cfac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (7.39s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-25</td>\n",
       "      <td>6.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-27</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  pm2_5\n",
       "0  2024-02-23   6.70\n",
       "1  2024-02-24   6.40\n",
       "2  2024-02-25   6.32\n",
       "3  2024-02-26   6.58\n",
       "4  2024-02-27   6.58"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch = invoke_function(functions[0], feature_view, model_air_quality)\n",
    "data_batch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb16e4",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>üß¨ Context Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fb16d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_data(user_query, model_llm, tokenizer, model_air_quality, encoder):\n",
    "    completion = generate_hermes(user_query, model_llm, tokenizer)\n",
    "    \n",
    "    functions = extract_function_calls(completion)\n",
    "    print(functions)\n",
    "    \n",
    "    if functions:\n",
    "        data = invoke_function(functions[0], feature_view, model_air_quality)\n",
    "        return '\\n'.join([f'Date: {row[1][\"date\"]}; Air Quality: {row[1][\"pm2_5\"]}' for row in data.iterrows()])\n",
    "\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71bd91c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_data_in_date_range', 'arguments': {'date_start': '2024-01-10', 'date_end': '2024-01-14', 'city_name': 'New York'}}]\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (7.53s) \n",
      "Date: 2024-01-10; Air Quality: 7.2\n",
      "Date: 2024-01-11; Air Quality: 5.9\n",
      "Date: 2024-01-12; Air Quality: 10.8\n",
      "Date: 2024-01-13; Air Quality: 5.9\n",
      "Date: 2024-01-14; Air Quality: 5.1\n"
     ]
    }
   ],
   "source": [
    "QUESTION1 = \"What was the air quality from 2024-01-10 till 2024-01-14 in New York?\"\n",
    "\n",
    "data_pred_q1 = get_context_data(QUESTION1, model_llm, tokenizer, model_air_quality, encoder)\n",
    "print(data_pred_q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c2c755d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_data_for_date', 'arguments': {'date': '2024-02-22', 'city_name': 'Amsterdam'}}]\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (7.49s) \n",
      "Date: 2024-02-22; Air Quality: 5.2\n"
     ]
    }
   ],
   "source": [
    "QUESTION2 = \"What was the air quality yesterday in Amsterdam?\"\n",
    "\n",
    "data_pred_q2 = get_context_data(QUESTION2, model_llm, tokenizer, model_air_quality, encoder)\n",
    "print(data_pred_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3221e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_future_data', 'arguments': {'date': '2024-02-27', 'city_name': 'London'}}]\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (7.86s) \n",
      "Date: 2024-02-23; Air Quality: 8.1\n",
      "Date: 2024-02-24; Air Quality: 7.45\n",
      "Date: 2024-02-25; Air Quality: 8.31\n",
      "Date: 2024-02-26; Air Quality: 8.57\n",
      "Date: 2024-02-27; Air Quality: 8.15\n"
     ]
    }
   ],
   "source": [
    "QUESTION3 = \"What will the air quality be like in London in 2024-02-27?\"\n",
    "\n",
    "data_pred_q3 = get_context_data(QUESTION3, model_llm, tokenizer, model_air_quality, encoder)\n",
    "print(data_pred_q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ed3ec9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_future_data', 'arguments': {'date': '2024-02-25', 'city_name': 'Chicago'}}]\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (7.63s) \n",
      "Date: 2024-02-23; Air Quality: 14.1\n",
      "Date: 2024-02-24; Air Quality: 12.87\n",
      "Date: 2024-02-25; Air Quality: 9.85\n"
     ]
    }
   ],
   "source": [
    "QUESTION4 = \"What will the air quality be like in Chicago the day after tomorrow?\"\n",
    "\n",
    "data_pred_q4 = get_context_data(QUESTION4, model_llm, tokenizer, model_air_quality, encoder)\n",
    "print(data_pred_q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39665b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_future_data', 'arguments': {'date': '2024-03-01', 'city_name': 'London'}}]\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (7.81s) \n",
      "Date: 2024-02-23; Air Quality: 8.1\n",
      "Date: 2024-02-24; Air Quality: 7.45\n",
      "Date: 2024-02-25; Air Quality: 8.31\n",
      "Date: 2024-02-26; Air Quality: 8.57\n",
      "Date: 2024-02-27; Air Quality: 8.15\n",
      "Date: 2024-02-28; Air Quality: 7.97\n",
      "Date: 2024-02-29; Air Quality: 7.97\n",
      "Date: 2024-03-01; Air Quality: 8.32\n"
     ]
    }
   ],
   "source": [
    "QUESTION5 = \"What will the air quality be like in London next Friday?\"\n",
    "\n",
    "data_pred_q5 = get_context_data(QUESTION5, model_llm, tokenizer, model_air_quality, encoder)\n",
    "print(data_pred_q5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b3d8312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "I am a machine learning model and I don't have feelings, but I am here to help you with your queries. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "QUESTION6 = \"How are you?\"\n",
    "\n",
    "data_pred_q6 = get_context_data(QUESTION6, model_llm, tokenizer, model_air_quality, encoder)\n",
    "print(data_pred_q6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1af9d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_future_data', 'arguments': {'date': '2024-03-01', 'city_name': 'Amsterdam'}}]\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (7.76s) \n",
      "Date: 2024-02-23; Air Quality: 6.7\n",
      "Date: 2024-02-24; Air Quality: 6.4\n",
      "Date: 2024-02-25; Air Quality: 6.32\n",
      "Date: 2024-02-26; Air Quality: 6.58\n",
      "Date: 2024-02-27; Air Quality: 6.58\n",
      "Date: 2024-02-28; Air Quality: 6.58\n",
      "Date: 2024-02-29; Air Quality: 6.54\n",
      "Date: 2024-03-01; Air Quality: 6.58\n"
     ]
    }
   ],
   "source": [
    "QUESTION7 = \"What will the air quality be like on March 1 in Amsterdam?\"\n",
    "\n",
    "data_pred_q7 = get_context_data(QUESTION7, model_llm, tokenizer, model_air_quality, encoder)\n",
    "print(data_pred_q7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1e6de",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
